{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\n",
      "ERROR: No matching distribution found for tensorflow\n",
      "WARNING: You are using pip version 20.0.2; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\machinelearning\\my_env\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-027e3bbea43f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresnet50\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mResNet50\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "#import alll required modules except ipython image will need to be imported multiple times because  the PIL function is also named image\n",
    "import numpy as np # linear algebra\n",
    "\n",
    "!pip install tensorflow\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from IPython.display import Image, display\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import matplotlib.image as img\n",
    "from PIL import Image\n",
    "from IPython.display import Image, display\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from learntools.deep_learning.exercise_1 import *\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from PIL import Image\n",
    "from IPython.display import Image, display\n",
    "\n",
    "#create some useful functions for viewingthe images  \n",
    "\n",
    "#visualise convolutiosn in black and white\n",
    "def visualize_conv(image, conv):\n",
    "    if conv == ____: # user hasn't written code. Return to avoid exception\n",
    "        return\n",
    "    conv_array = np.array(conv)\n",
    "    vertical_padding = conv_array.shape[0] - 1\n",
    "    horizontal_padding = conv_array.shape[1] - 1\n",
    "    conv_out = scale_for_display(apply_conv_to_image(conv_array, image),\n",
    "                                contrast_factor=350)\n",
    "    show(np.hstack([image[:-vertical_padding, :-horizontal_padding], conv_out]), False)\n",
    "    \n",
    "#read and prepare the images using their images paths - define chosen image width and height here - This will ammend the images so they are all the same\n",
    "image_size = 224\n",
    "\n",
    "def read_and_prep_images(img_paths, img_height=image_size, img_width=image_size):\n",
    "    imgs = [load_img(img_path, target_size=(img_height, img_width)) for img_path in img_paths]\n",
    "    img_array = np.array([img_to_array(img) for img in imgs])\n",
    "    output = preprocess_input(img_array)\n",
    "    return(output)\n",
    "\n",
    "#function to decode predictions using the existing keras library\n",
    "\n",
    "def decode_predictions(preds, top=5, class_list_path='datasets_2798_7251_imagenet_class_index.json'):\n",
    "  \"\"\"Decodes the prediction of an ImageNet model.\n",
    "  Arguments:\n",
    "      preds: Numpy tensor encoding a batch of predictions.\n",
    "      top: integer, how many top-guesses to return.\n",
    "      class_list_path: Path to the canonical imagenet_class_index.json file\n",
    "  Returns:\n",
    "      A list of lists of top class prediction tuples\n",
    "      `(class_name, class_description, score)`.\n",
    "      One list of tuples per sample in batch input.\n",
    "  Raises:\n",
    "      ValueError: in case of invalid shape of the `pred` array\n",
    "          (must be 2D).\n",
    "  \"\"\"\n",
    "  if len(preds.shape) != 2 or preds.shape[1] != 1000:\n",
    "    raise ValueError('`decode_predictions` expects '\n",
    "                     'a batch of predictions '\n",
    "                     '(i.e. a 2D array of shape (samples, 1000)). '\n",
    "                     'Found array with shape: ' + str(preds.shape))\n",
    "  CLASS_INDEX = json.load(open(class_list_path))\n",
    "  results = []\n",
    "  for pred in preds:\n",
    "    top_indices = pred.argsort()[-top:][::-1]\n",
    "    result = [tuple(CLASS_INDEX[str(i)]) + (pred[i],) for i in top_indices]\n",
    "    result.sort(key=lambda x: x[2], reverse=True)\n",
    "    results.append(result)\n",
    "  return results\n",
    "\n",
    "\n",
    "def load_image(fname = '../CAT_01/cat.jpg'):\n",
    "    '''returns array containing greyscale values for supplied file (at thumbnail size)'''\n",
    "    image_color = Image.open(fname).resize((135, 188), Image.ANTIALIAS)\n",
    "    image_grayscale = image_color.convert('L')\n",
    "    image_array = np.asarray(image_grayscale)\n",
    "    return(image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"../CAT_01\")\n",
    "\n",
    "file_list = []\n",
    "for root, dirs, files in os.walk(\"../CAT_01\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".jpg\"):    \n",
    "            file_list.append(file)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import Image, display#checkout the pics\n",
    "\n",
    "display(Image('../CAT_01.CAT.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at the convolution effects on my imagegs \n",
    "from PIL import Image\n",
    "#create a convolutions\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.deep_learning.exercise_1 import *\n",
    "horizontal_line_conv = [[1, 1], \n",
    "                        [-1, -1]]\n",
    "\n",
    "#horizontal_line_conv = [[1000,1000],[1000,0]]\n",
    "ok  = load_image()\n",
    "visualize_conv(ok,horizontal_line_conv )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_conv = [[1, 5,1], \n",
    "                        [-1, 3,-1],\n",
    "                       [1,5,1]]\n",
    "\n",
    "#horizontal_line_conv = [[1000,1000],[1000,0]]\n",
    "ok  = load_image()\n",
    "visualize_conv(ok,another_conv )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "imag = img.imread('/kaggle/input/cat-dataset/cats/CAT_01/00000298_001.jpg')\n",
    "print(imag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#create a list of the file names \n",
    "filenamelist = []\n",
    "for i in file_list:\n",
    "    filenamelist.append('/kaggle/input/cat-dataset/cats/CAT_00/'+i)\n",
    "print(filenamelist[1])\n",
    "\n",
    "len(filenamelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenamelist.append('../input/mydandy/cat.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filenamelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.display import Image, display\n",
    "from IPython.display import Image, display\n",
    "\n",
    "img_paths = '/kaggle/input/cat-dataset/cats/CAT_00'\n",
    "for i, img_path in enumerate(filenamelist[0:4]):\n",
    "    display(Image(img_path))\n",
    "    #print(most_likely_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#this section  of code takes the longest - there is not a set of images that are already labelled for these cats which is why we use the existing keras library \n",
    "\n",
    "#use earlier functions to prepare the images\n",
    "catmat = read_and_prep_images(filenamelist)\n",
    "\n",
    "#create model using resnet weights\n",
    "\n",
    "my_model = ResNet50(weights='imagenet')\n",
    "\n",
    "#make predictions of the data set \n",
    "\n",
    "preds = my_model.predict(catmat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use decode_predictions  function with the already created keras lib to predict cat species and/or other items in the picture \n",
    "most_likely_labels = decode_predictions(preds, top=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "#enumerate through the file names and print out the image and the predictions as well as likelyhood\n",
    "\n",
    "for i, img_path in enumerate(filenamelist[10:20]):\n",
    "    display(Image(img_path))\n",
    "    #print(most_likely_labels[i])\n",
    "    print(most_likely_labels[i])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(1, 1))\n",
    "from IPython.display import Image, display\n",
    "for i, img_path in enumerate(filenamelist[-1:]):\n",
    "    print(img_path)\n",
    "    display(Image(img_path))\n",
    "    #print(most_likely_labels[i])\n",
    "    print(most_likely_labels[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
